*** src/ReClaM/Svm.cpp	2010-12-20 19:23:24.000000000 +0100
--- src/ReClaM/mySvm.cpp	2012-05-16 17:28:11.329988953 +0200
***************
*** 948,953 ****
--- 948,1112 ----
  	}
  }
  
+ bool MultiClassSVM::LoadSVMModel(std::istream& is)
+ {
+ 	char buffer[50];
+ 	unsigned int t, d;
+ 
+ 	// read the header line
+ 	is.read(buffer, 33);
+ 
+ 	buffer[33] = 0;
+ 	if (strcmp(buffer, "Shark Multi Class SVM model\r\nSV: ") != 0) return false;
+ 	if (! is.good()) return false;
+ 
+ 	// read the number of support vectors
+ 	is >> examples;
+ 
+ 	is.read(buffer, 7); buffer[7] = 0;
+ 	if (strcmp(buffer, "\r\nDIM: ") != 0) return false;
+ 	if (! is.good()) return false;
+ 
+ 	// read the input space dimension
+ 	is >> inputDimension;
+ 
+ 	is.read(buffer, 10); buffer[10] = 0;
+ 	if (strcmp(buffer, "\r\nkernel: ") != 0) return false;
+ 	if (! is.good()) return -6;
+ 
+ 	// read the kernel parameters
+ 	is >> (*kernel);
+ 
+ 	is.read(buffer, 9); buffer[9] = 0;
+ 	if(strcmp(buffer, "classes: ") != 0) return false;
+ 
+ 	// read the number of classes
+ 	is >> classes;
+ 
+ 	is.read(buffer, 16); buffer[16] = 0;
+ 	if (strcmp(buffer, "\r\ncoefficients: ") != 0) return false;
+ 	if (! is.good()) return false;
+ 
+ 	// read alpha and b
+ 	parameter.resize((examples + 1)*classes, false);
+ 	for (t = 0; t < (examples+1)*classes; t++)
+ 	{
+ 		is >> parameter(t);
+ 		is.read(buffer, 1);
+ 		if (buffer[0] != ' ') return false;
+ 	}
+ 
+ 	is.read(buffer, 2); buffer[2] = 0;
+ 	if (strcmp(buffer, "\r\n") != 0) return false;
+ 	if (! is.good()) return -10;
+ 
+ 	// read the support vectors
+ 	Array<double>* sv = new Array<double> (examples, inputDimension);
+ 	Array<double>* sy = new Array<double> (examples, 1);
+ 
+ 	for (t = 0; t < examples; t++)
+ 	{
+ 		for (d = 0; d < inputDimension; d++)
+ 		{
+ 			is >> (*sv)(t, d);
+ 			if (d < inputDimension - 1)
+ 			{
+ 				is.read(buffer, 1);
+ 				if (buffer[0] != ' ') return false;
+ 			}
+ 		}
+ 
+ 		is.read(buffer, 2); buffer[2] = 0;
+ 		if (strcmp(buffer, "\r\n") != 0) return false;
+ 
+ 		is >> (*sy)(t);
+ 
+ 		is.read(buffer, 2); buffer[2] = 0;
+ 		if (strcmp(buffer, "\r\n") != 0) return false;
+ 
+ 		if (! is.good()) return -14;
+ 	}
+ 
+ 	bOwnMemory = true;
+ 	x = sv;
+ 	y = sy;
+ 
+ 	return true;
+ }
+ 
+ bool MultiClassSVM::SaveSVMModel(std::ostream& os)
+ {
+ 	unsigned int t, d, c, i = 0;
+ 	unsigned int T = 0;
+ 	for (t=0; t<examples; t++)
+ 	{
+ 		for (c=0; c<classes; c++) if (parameter(i + c) != 0.0) break;
+ 		if (c < classes)
+ 		{
+ 			T++;
+ 		}
+ 		i += classes;
+ 	}
+ 
+ 	// write the header line
+ 	os.write("Shark Multi Class SVM model\r\nSV: ", 33);
+ 
+ 	// write the number of support vectors
+ 	os << T;
+ 
+ 	os.write("\r\nDIM: ", 7);
+ 	if (! os.good()) return false;
+ 
+ 	// write the input space dimension
+ 	os << inputDimension;
+ 
+ 	os.write("\r\nkernel: ", 10);
+ 	if (! os.good()) return false;
+ 
+ 	// write the kernel parameters
+ 	os << (*kernel);
+ 
+ 	// write the number of classes
+ 	os.write("classes: ", 9);
+ 	os << classes << "\r\n";
+ 
+ 	os.write("coefficients: ", 14);
+ 	if (! os.good()) return false;
+ 
+ 	// write alpha and b
+ 	for (t = 0; t < (examples+1)*classes; t++) /*if (parameter(t) != 0.0)*/ os << parameter(t) << " ";
+ 	os << /*parameter(examples*classes) << */ "\r\n";
+ 	if (! os.good()) return false;
+ 
+ 
+ 	// write the support vectors
+ 	for (t = 0; t < examples; t++)
+ 	{
+ //		if (parameter(t * classes + c) != 0.0)
+ 		{
+ 			for (d = 0; d < inputDimension; d++)
+ 			{
+ 				if(isnan((*x)(t, d))) {
+ 					std::cerr << "x[" << (t, d) << "] is NAN\n";
+ 					return false;
+ 				}
+ 
+ 				os << (*x)(t, d);
+ 				if (d < inputDimension - 1) os << " ";
+ 			}
+ 			os.write("\r\n", 2);
+ 			if(isnan((*y)(t))) {
+ 				std::cerr << "y[" << (t * classes + c) << "] is NAN\n";
+ 				return false;
+ 			}
+ 			os << (*y)(t);
+ 			os.write("\r\n", 2);
+ 			if (! os.good()) return false;
+ 		}
+ 	}
+ 
+ 	return true;
+ }
  
  ////////////////////////////////////////////////////////////////////////////////
  
***************
*** 1608,1614 ****
  	}
  }
  
- 
  ////////////////////////////////////////////////////////////////////////////////
  
  
--- 1767,1772 ----
